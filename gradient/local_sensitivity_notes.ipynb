{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Gradient Based Optimization\n",
    "Notes copied from Marcels presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global methods with local gradient information\n",
    "\n",
    "Several algorithms combine a global approach (to avoid getting stuck in local minima) with a local gradient approach (to quickly find the best values in a certain region), e.g. the \"basin hopping\" algorithm.\n",
    "\n",
    "### Local gradient\n",
    "For an ODE system of variables $\\mathbf{x}$ with parameters $\\mathbf{p}$ that we are interested in:\n",
    "$$\n",
    "\\frac{\\mathrm{d}\\mathbf{x}(t; \\mathbf{p})}{\\mathrm{d}t} = f(\\mathbf{x}, t; \\mathbf{p}) \n",
    "$$\n",
    "\n",
    "we want to know how the solution changes with changes in the parameters:\n",
    "$$\n",
    "\\frac{\\delta\\mathbf{x}(t; \\mathbf{p})}{\\delta\\mathbf{p}}\n",
    "$$\n",
    "\n",
    "This is called the *local sensitivity*.\n",
    "\n",
    "*Note:* For optimization, we are in general only interested in the gradient of the error function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get local gradient?\n",
    "\n",
    "**Numerically** (often default in optimiztion algorithms): finite difference approximation\n",
    "\n",
    "For each parameter $p_i$:\n",
    "$$\n",
    "\\frac{\\delta\\mathbf{x}(t; \\mathbf{p})}{\\delta p_i} \\approx \\frac{\\mathbf{x}(t; \\mathbf{p} + \\mathbf{e_i}\\Delta p_i) - \\mathbf{x}(t; \\mathbf{p})}{\\Delta p_i}\n",
    "$$\n",
    "\n",
    "This is problematic for ODEs:\n",
    "* Difficult to chose $p_i$\n",
    "* Numerical errors in the numerical integration of $\\mathbf{x}(t; \\mathbf{p})$ add up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially better approach: *local forward sensitivity analysis*\n",
    "\n",
    "Extend ODE system to include new variables:\n",
    "$$\n",
    "S_{ij} :=  \\frac{\\delta x_i}{\\delta p_j}\n",
    "$$\n",
    "\n",
    "(from now on using usual short-hand notation, e.g. $x_i$ instead of $x_i(t; \\mathbf{p})$)\n",
    "\n",
    "Evolution of these variables as ODEs:\n",
    "$$\n",
    "\\frac{\\mathrm{d}\\mathbf{S}_{j}}{\\mathrm{d}t} = \\mathbf{J}\\,\\mathbf{S}_{j} + \\mathbf{F}_j,\n",
    "$$\n",
    "\n",
    "where: \n",
    "$$\n",
    "\\mathbf{J} = \n",
    "\\begin{pmatrix}\n",
    "\\frac{\\delta f_1}{\\delta x_1} & \\frac{\\delta f_1}{\\delta x_2} & \\cdots & \\frac{\\delta f_1}{\\delta x_n}\\\\\n",
    "\\frac{\\delta f_2}{\\delta x_1} & \\frac{\\delta f_2}{\\delta x_2} & \\cdots & \\frac{\\delta f_2}{\\delta x_n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\delta f_n}{\\delta x_1} & \\frac{\\delta f_n}{\\delta x_2} & \\cdots & \\frac{\\delta f_n}{\\delta x_n}\\\\\n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathbf{F}_j = \n",
    "\\begin{pmatrix}\n",
    "\\frac{\\delta f_1}{\\delta p_j}\\\\\n",
    "\\frac{\\delta f_2}{\\delta p_j}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\delta f_n}{\\delta p_j}\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We can then solve the full system with the usual numerical integration algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensitivity_equations(group, parameters):\n",
    "    eqs = group.equations\n",
    "    diff_eqs = eqs.get_substituted_expressions(group.variables)\n",
    "    diff_eq_names = [name for name, _ in diff_eqs]\n",
    "\n",
    "    system = Matrix([diff_eq[1] for diff_eq in diff_eqs])\n",
    "    J = system.jacobian(diff_eq_names)\n",
    "\n",
    "    sensitivity = []\n",
    "    sensitivity_names = []\n",
    "    for parameter in parameters:\n",
    "        F = system.jacobian([parameter])\n",
    "        names = ['S_{}_{}'.format(diff_eq_name, parameter)\n",
    "                 for diff_eq_name in diff_eq_names]\n",
    "        sensitivity.append(J * Matrix(names) + F)\n",
    "        sensitivity_names.append(names)\n",
    "\n",
    "    new_eqs = []\n",
    "    for names, sensitivity_eqs, param in zip(sensitivity_names, sensitivity, parameters):\n",
    "        for name, eq, orig_var in zip(names, sensitivity_eqs, diff_eq_names):\n",
    "            unit = eqs[orig_var].dim / group.namespace[parameter].dim\n",
    "            new_eqs.append('d{lhs}/dt = {rhs} : {unit}'.format(lhs=name,\n",
    "                                                           rhs=eq,\n",
    "                                                           unit=repr(unit)))\n",
    "    new_eqs = Equations('\\n'.join(new_eqs))\n",
    "    return new_eqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brian_opt",
   "language": "python",
   "name": "brian_opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
